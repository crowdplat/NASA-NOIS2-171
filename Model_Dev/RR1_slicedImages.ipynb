{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "import os\n",
    "import torchvision.models as models\n",
    "from torchvision.models import ResNet18_Weights\n",
    "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from monai.networks.nets import DenseNet121, UNet\n",
    "from monai.networks.nets import DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_channels = 1\n",
    "image_size = (224, 224)\n",
    "# image_size = (1024, 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImprovedCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ImprovedCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(image_channels, 32, kernel_size=3, padding=1)  \n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "\n",
    "        self.flattened_size = 256 * (image_size[0] // 16) * (image_size[1] // 16)\n",
    "        self.fc1 = nn.Linear(self.flattened_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(torch.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(torch.relu(self.bn3(self.conv3(x))))\n",
    "        x = self.pool(torch.relu(self.conv4(x)))\n",
    "        x = x.view(-1, self.flattened_size)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        # x = torch.sigmoid(self.fc2(x))\n",
    "        return self.fc2(x)\n",
    "\n",
    "class TransferLearningModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TransferLearningModel, self).__init__()\n",
    "        # Load pre-trained ResNet18 with weights\n",
    "        self.base_model = models.resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "        \n",
    "        # Modify the first convolutional layer to accept grayscale input\n",
    "        self.base_model.conv1 = nn.Conv2d(image_channels, 64, kernel_size=3, padding=1) \n",
    "        \n",
    "        # Replace the fully connected layer for binary classification\n",
    "        num_features = self.base_model.fc.in_features\n",
    "        self.base_model.fc = nn.Linear(num_features, 1)  # Output 1 raw logit\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.base_model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_monai_model():\n",
    "    # Load MONAI's DenseNet121\n",
    "    model = DenseNet121(\n",
    "        spatial_dims=2,  # For 2D images\n",
    "        in_channels=image_channels,   # RGB input\n",
    "        out_channels=1   # Binary classification (logits)\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def get_densenet169():\n",
    "    model = DenseNet(\n",
    "        spatial_dims=2,\n",
    "        in_channels=image_channels,\n",
    "        out_channels=1,  # Binary classification\n",
    "        block_config=(6, 12, 32, 32)  # DenseNet169 configuration\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "class FullImageDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load the image as a NumPy array\n",
    "        image = np.load(self.image_paths[idx])  # Shape: [224, 224]\n",
    "\n",
    "        # # Load the image as a JPG\n",
    "        # image = np.array(Image.open(self.image_paths[idx]))\n",
    "        \n",
    "        # Scale pixel values to [0, 255] if they are normalized\n",
    "        if image.max() <= 1.0:  # Check if image is normalized\n",
    "            image = (image * 255).astype(np.uint8)\n",
    "        \n",
    "        # Convert NumPy array to PIL Image\n",
    "        image = Image.fromarray(image)\n",
    "        \n",
    "        # Apply transformations if provided\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # # Convert to PyTorch tensor\n",
    "        # image = torch.tensor(image, dtype=torch.float32)\n",
    "\n",
    "        # Convert label to PyTorch tensor\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example file\n",
    "# image_path = '../rr1_dataset/img_input/LSDS-2_Histology_M16-M17-M18_HE.jpg'\n",
    "\n",
    "# img = Image.open(image_path)\n",
    "\n",
    "# intermediate_size = (img.size[0] // 4, img.size[1] // 4)\n",
    "# img_intermediate = img.resize(intermediate_size, Image.Resampling.NEAREST)\n",
    "# img_resized = img_intermediate.resize(image_size, Image.Resampling.NEAREST)\n",
    "\n",
    "# img_array = np.array(img_resized) / 255.0\n",
    "\n",
    "# plt.imshow(img_array)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LOOCV Function\n",
    "def loocv_full_image_with_augmentation(image_paths, labels, num_epochs=100, learning_rate=0.0001, save_dir=\"../Models\"):\n",
    "    os.makedirs(save_dir, exist_ok=True)  # Ensure the save directory exists\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    true_labels = []\n",
    "    image_pred_prob = []\n",
    "    image_pred_label = []\n",
    "    \n",
    "    # Define augmentations for the training dataset - Grayscale\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize(image_size),             # Resize all images\n",
    "        # transforms.RandomHorizontalFlip(p=0.5),  # Flip horizontally with 50% probability\n",
    "        # transforms.RandomVerticalFlip(p=0.5),    # Flip vertically with 50% probability\n",
    "        transforms.RandomRotation(10),           # Rotate randomly within ±10 degrees\n",
    "        transforms.RandomResizedCrop(size=(image_size[0], image_size[1]), scale=(0.9, 1.0)),\n",
    "        transforms.ToTensor(),                   # Convert PIL Image to PyTorch tensor\n",
    "        transforms.Normalize(mean=[0.5], std=[0.5])  # Normalize to [-1, 1]\n",
    "    ])\n",
    "    \n",
    "    # Define transform for test dataset (no augmentation, only normalization) - Grayscale\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.Resize(image_size),             # Resize all images\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5], std=[0.5])  # Normalize to [-1, 1]\n",
    "    ])\n",
    "\n",
    "    # # Define augmentations for the training dataset - RGB\n",
    "    # train_transform = transforms.Compose([\n",
    "    #     transforms.Resize(image_size),             # Resize all images\n",
    "    #     transforms.RandomRotation(10),            # Rotate randomly within ±10 degrees\n",
    "    #     transforms.RandomResizedCrop(size=(image_size), scale=(0.9, 1.0)),\n",
    "    #     transforms.ToTensor(),                    # Convert PIL Image to PyTorch tensor\n",
    "    #     transforms.Normalize(mean=[0.485, 0.456, 0.406],  # Normalize RGB values\n",
    "    #                         std=[0.229, 0.224, 0.225])\n",
    "    # ])\n",
    "\n",
    "    # # Define transform for the test dataset (no augmentation, only resizing and normalization) - RGB\n",
    "    # test_transform = transforms.Compose([\n",
    "    #     transforms.Resize(image_size),            # Resize all images\n",
    "    #     transforms.ToTensor(),\n",
    "    #     transforms.Normalize(mean=[0.485, 0.456, 0.406],  # Normalize RGB values\n",
    "    #                         std=[0.229, 0.224, 0.225])\n",
    "    # ])\n",
    "\n",
    "    for test_image_id in range(len(image_paths)):\n",
    "        print(f\"Processing LOOCV for test image {test_image_id + 1}/{len(image_paths)}\")\n",
    "\n",
    "        # Split dataset into training and test sets\n",
    "        train_images = [image_paths[i] for i in range(len(image_paths)) if i != test_image_id]\n",
    "        train_labels = [labels[i] for i in range(len(labels)) if i != test_image_id]\n",
    "        test_image = image_paths[test_image_id]\n",
    "        test_label = labels[test_image_id]\n",
    "\n",
    "        # Create datasets and dataloaders\n",
    "        train_dataset = FullImageDataset(train_images, train_labels, transform=train_transform)\n",
    "        test_dataset = FullImageDataset([test_image], [test_label], transform=test_transform)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "        # # Visualize augmented images\n",
    "        # for i in range(1):\n",
    "        #     augmented_image, _ = train_dataset[np.random.randint(10)]  # Get augmented image\n",
    "        #     plt.imshow(augmented_image.squeeze().numpy().T)  # Visualize\n",
    "        #     plt.title(\"Augmented Image\")\n",
    "        #     plt.show()\n",
    "\n",
    "        # Initialize model, loss function, and optimizer\n",
    "        model = ImprovedCNN().to(device)\n",
    "        # model = TransferLearningModel().to(device)\n",
    "        # model = get_monai_model().to(device)\n",
    "        # model = get_densenet169().to(device)\n",
    "        \n",
    "\n",
    "        class_weights = compute_class_weight('balanced', classes=np.unique(train_labels), y=train_labels)\n",
    "        class_weights = torch.tensor(class_weights, dtype=torch.float)\n",
    "        # print(\"class_weights\", class_weights)\n",
    "\n",
    "        # criterion = nn.BCELoss()\n",
    "        criterion = nn.BCEWithLogitsLoss(pos_weight=class_weights[1])\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "        # Training loop\n",
    "        model.train()\n",
    "        for epoch in range(num_epochs):\n",
    "            for inputs, targets in train_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device).unsqueeze(1)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        # Testing loop\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for inputs, _ in test_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                outputs = model(inputs).squeeze()\n",
    "                probs = torch.sigmoid(outputs).cpu().numpy()  # Apply sigmoid for probabilities\n",
    "                image_pred_prob.append(probs)\n",
    "                pred_label = 1 if probs > 0.5 else 0\n",
    "                image_pred_label.append(pred_label)\n",
    "                true_labels.append(test_label)\n",
    "                print('Test pred prob:', probs, 'True label:', test_label, \"test_image\", test_image)\n",
    "\n",
    "    # Save the final trained model\n",
    "    final_model_path = os.path.join(save_dir, \"rr1_cnn_\"+str(image_size[0])+\".pth\")\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict()\n",
    "    }, final_model_path)\n",
    "    print(f\"Final model saved to {final_model_path}\")\n",
    "\n",
    "    return true_labels, image_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_dir = '../rr1_dataset/preprocessed_images/'\n",
    "\n",
    "# label_dict = {\n",
    "#     image_dir+'LSDS-2_Histology_M16-M17-M18_HE.npy': 0, #'Vivarium Control',\n",
    "#     image_dir+'LSDS-2_Histology_M16-M17-M18_ORO.npy': 0, #'Vivarium Control',\n",
    "#     image_dir+'LSDS-2_Histology_M19-M20_HE.npy': 0, #'Vivarium Control',\n",
    "#     image_dir+'LSDS-2_Histology_M19-M20_ORO.npy': 0, #'Vivarium Control',\n",
    "#     image_dir+'LSDS-2_Histology_M21-M22_HE.npy': 1, #'Space Flight',\n",
    "#     image_dir+'LSDS-2_Histology_M21-M22_ORO.npy': 1, #'Space Flight',\n",
    "#     image_dir+'LSDS-2_Histology_M25-M26-M27_HE.npy': 1, #'Space Flight',\n",
    "#     image_dir+'LSDS-2_Histology_M25-M26-M27_ORO.npy': 1, #'Space Flight',\n",
    "#     image_dir+'LSDS-2_Histology_M28-M30_HE.npy' : 1, #'Space Flight',\n",
    "#     image_dir+'LSDS-2_Histology_M28-M30_ORO.npy' : 1, #'Space Flight',\n",
    "#     image_dir+'LSDS-2_Histology_M31-M32_HE.npy': 0, #'Ground Control',\n",
    "#     image_dir+'LSDS-2_Histology_M31-M32_ORO.npy': 0, #'Ground Control',\n",
    "#     image_dir+'LSDS-2_Histology_M36-M37-M38_HE.npy': 0, #'Ground Control',\n",
    "#     image_dir+'LSDS-2_Histology_M36-M37-M38_ORO.npy': 0, #'Ground Control',\n",
    "#     image_dir+'LSDS-2_Histology_M39-M40_HE.npy': 0, #'Ground Control',\n",
    "#     image_dir+'LSDS-2_Histology_M39-M40_ORO.npy': 0, #'Ground Control',\n",
    "#     image_dir+'LSDS-2_Histology_M4-M5-M7_HE.npy': 0, #'Basal Control',\n",
    "#     image_dir+'LSDS-2_Histology_M4-M5-M7_ORO.npy': 0, #'Basal Control',\n",
    "#     image_dir+'LSDS-2_Histology_M8-M10_HE.npy': 0, #'Basal Control',\n",
    "#     image_dir+'LSDS-2_Histology_M8-M10_ORO.npy': 0, #'Basal Control',\n",
    "# }\n",
    "\n",
    "image_dir = '../rr1_dataset/preprocessed_images/'\n",
    "\n",
    "# label_dict = {\n",
    "#     image_dir+'LSDS-2_Histology_M16-M17-M18_HE.npy': 0, #'Vivarium Control',\n",
    "#     image_dir+'LSDS-2_Histology_M19-M20_HE.npy': 0, #'Vivarium Control',\n",
    "#     image_dir+'LSDS-2_Histology_M21-M22_HE.npy': 1, #'Space Flight',\n",
    "#     image_dir+'LSDS-2_Histology_M25-M26-M27_HE.npy': 1, #'Space Flight',\n",
    "#     image_dir+'LSDS-2_Histology_M28-M30_HE.npy' : 1, #'Space Flight',\n",
    "#     image_dir+'LSDS-2_Histology_M31-M32_HE.npy': 0, #'Ground Control',\n",
    "#     image_dir+'LSDS-2_Histology_M36-M37-M38_HE.npy': 0, #'Ground Control',\n",
    "#     image_dir+'LSDS-2_Histology_M39-M40_HE.npy': 0, #'Ground Control',\n",
    "#     image_dir+'LSDS-2_Histology_M4-M5-M7_HE.npy': 0, #'Basal Control',\n",
    "#     image_dir+'LSDS-2_Histology_M8-M10_HE.npy': 0, #'Basal Control',\n",
    "# }\n",
    "\n",
    "label_dict = {\n",
    "    image_dir+'LSDS-2_Histology_M16-M17-M18-1_ORO.npy': 0, #'Vivarium Control',\n",
    "    image_dir+'LSDS-2_Histology_M16-M17-M18-2_ORO.npy': 0, #'Vivarium Control',\n",
    "    image_dir+'LSDS-2_Histology_M16-M17-M18-3_ORO.npy': 0, #'Vivarium Control',\n",
    "\n",
    "    image_dir+'LSDS-2_Histology_M19-M20-1_ORO.npy': 0, #'Vivarium Control',\n",
    "    image_dir+'LSDS-2_Histology_M19-M20-2_ORO.npy': 0, #'Vivarium Control',\n",
    "    image_dir+'LSDS-2_Histology_M19-M20-3_ORO.npy': 0, #'Vivarium Control',\n",
    "\n",
    "    image_dir+'LSDS-2_Histology_M21-M22-1_ORO.npy': 1, #'Space Flight',\n",
    "    image_dir+'LSDS-2_Histology_M21-M22-2_ORO.npy': 1, #'Space Flight',\n",
    "    image_dir+'LSDS-2_Histology_M21-M22-3_ORO.npy': 1, #'Space Flight',\n",
    "\n",
    "    image_dir+'LSDS-2_Histology_M25-M26-M27-1_ORO.npy': 1, #'Space Flight',\n",
    "    image_dir+'LSDS-2_Histology_M25-M26-M27-2_ORO.npy': 1, #'Space Flight',\n",
    "    image_dir+'LSDS-2_Histology_M25-M26-M27-3_ORO.npy': 1, #'Space Flight',\n",
    "    image_dir+'LSDS-2_Histology_M25-M26-M27-4_ORO.npy': 1, #'Space Flight',\n",
    "\n",
    "    image_dir+'LSDS-2_Histology_M28-M30-1_ORO.npy' : 1, #'Space Flight',\n",
    "    image_dir+'LSDS-2_Histology_M28-M30-2_ORO.npy' : 1, #'Space Flight',\n",
    "    image_dir+'LSDS-2_Histology_M28-M30-3_ORO.npy' : 1, #'Space Flight',\n",
    "\n",
    "    image_dir+'LSDS-2_Histology_M31-M32-1_ORO.npy': 0, #'Ground Control',\n",
    "    image_dir+'LSDS-2_Histology_M31-M32-2_ORO.npy': 0, #'Ground Control',\n",
    "    image_dir+'LSDS-2_Histology_M31-M32-3_ORO.npy': 0, #'Ground Control',\n",
    "\n",
    "    image_dir+'LSDS-2_Histology_M36-M37-M38-1_ORO.npy': 0, #'Ground Control',\n",
    "    image_dir+'LSDS-2_Histology_M36-M37-M38-2_ORO.npy': 0, #'Ground Control',\n",
    "    image_dir+'LSDS-2_Histology_M36-M37-M38-3_ORO.npy': 0, #'Ground Control',\n",
    "    image_dir+'LSDS-2_Histology_M36-M37-M38-4_ORO.npy': 0, #'Ground Control',\n",
    "\n",
    "    image_dir+'LSDS-2_Histology_M39-M40-1_ORO.npy': 0, #'Ground Control',\n",
    "    image_dir+'LSDS-2_Histology_M39-M40-2_ORO.npy': 0, #'Ground Control',\n",
    "    image_dir+'LSDS-2_Histology_M39-M40-3_ORO.npy': 0, #'Ground Control',\n",
    "\n",
    "    image_dir+'LSDS-2_Histology_M4-M5-M7-1_ORO.npy': 0, #'Basal Control',\n",
    "    image_dir+'LSDS-2_Histology_M4-M5-M7-2_ORO.npy': 0, #'Basal Control',\n",
    "    image_dir+'LSDS-2_Histology_M4-M5-M7-3_ORO.npy': 0, #'Basal Control',\n",
    "    image_dir+'LSDS-2_Histology_M4-M5-M7-4_ORO.npy': 0, #'Basal Control',\n",
    "\n",
    "    image_dir+'LSDS-2_Histology_M8-M10-1_ORO.npy': 0, #'Basal Control',\n",
    "    image_dir+'LSDS-2_Histology_M8-M10-2_ORO.npy': 0, #'Basal Control',\n",
    "    image_dir+'LSDS-2_Histology_M8-M10-3_ORO.npy': 0, #'Basal Control'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = list(label_dict.keys()) # Replace with actual .npy file paths\n",
    "labels = list(label_dict.values())  # Replace with actual labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing LOOCV for test image 1/33\n",
      "Test pred prob: 3.1904196e-07 True label: 0 test_image ../rr1_dataset/preprocessed_images/LSDS-2_Histology_M16-M17-M18-1_ORO.npy\n",
      "Processing LOOCV for test image 2/33\n",
      "Test pred prob: 0.98675597 True label: 0 test_image ../rr1_dataset/preprocessed_images/LSDS-2_Histology_M16-M17-M18-2_ORO.npy\n",
      "Processing LOOCV for test image 3/33\n",
      "Test pred prob: 6.9036435e-07 True label: 0 test_image ../rr1_dataset/preprocessed_images/LSDS-2_Histology_M16-M17-M18-3_ORO.npy\n",
      "Processing LOOCV for test image 4/33\n",
      "Test pred prob: 0.99981683 True label: 0 test_image ../rr1_dataset/preprocessed_images/LSDS-2_Histology_M19-M20-1_ORO.npy\n",
      "Processing LOOCV for test image 5/33\n",
      "Test pred prob: 3.0166817e-07 True label: 0 test_image ../rr1_dataset/preprocessed_images/LSDS-2_Histology_M19-M20-2_ORO.npy\n",
      "Processing LOOCV for test image 6/33\n",
      "Test pred prob: 1.5898648e-09 True label: 0 test_image ../rr1_dataset/preprocessed_images/LSDS-2_Histology_M19-M20-3_ORO.npy\n",
      "Processing LOOCV for test image 7/33\n",
      "Test pred prob: 0.99930656 True label: 1 test_image ../rr1_dataset/preprocessed_images/LSDS-2_Histology_M21-M22-1_ORO.npy\n",
      "Processing LOOCV for test image 8/33\n",
      "Test pred prob: 0.99446905 True label: 1 test_image ../rr1_dataset/preprocessed_images/LSDS-2_Histology_M21-M22-2_ORO.npy\n",
      "Processing LOOCV for test image 9/33\n",
      "Test pred prob: 0.98604894 True label: 1 test_image ../rr1_dataset/preprocessed_images/LSDS-2_Histology_M21-M22-3_ORO.npy\n",
      "Processing LOOCV for test image 10/33\n",
      "Test pred prob: 0.20296022 True label: 1 test_image ../rr1_dataset/preprocessed_images/LSDS-2_Histology_M25-M26-M27-1_ORO.npy\n",
      "Processing LOOCV for test image 11/33\n",
      "Test pred prob: 0.9982085 True label: 1 test_image ../rr1_dataset/preprocessed_images/LSDS-2_Histology_M25-M26-M27-2_ORO.npy\n",
      "Processing LOOCV for test image 12/33\n",
      "Test pred prob: 0.99797326 True label: 1 test_image ../rr1_dataset/preprocessed_images/LSDS-2_Histology_M25-M26-M27-3_ORO.npy\n",
      "Processing LOOCV for test image 13/33\n",
      "Test pred prob: 0.86491424 True label: 1 test_image ../rr1_dataset/preprocessed_images/LSDS-2_Histology_M25-M26-M27-4_ORO.npy\n",
      "Processing LOOCV for test image 14/33\n",
      "Test pred prob: 0.834136 True label: 1 test_image ../rr1_dataset/preprocessed_images/LSDS-2_Histology_M28-M30-1_ORO.npy\n",
      "Processing LOOCV for test image 15/33\n",
      "Test pred prob: 0.70513743 True label: 1 test_image ../rr1_dataset/preprocessed_images/LSDS-2_Histology_M28-M30-2_ORO.npy\n",
      "Processing LOOCV for test image 16/33\n",
      "Test pred prob: 0.00048383843 True label: 1 test_image ../rr1_dataset/preprocessed_images/LSDS-2_Histology_M28-M30-3_ORO.npy\n",
      "Processing LOOCV for test image 17/33\n",
      "Test pred prob: 0.0016889852 True label: 0 test_image ../rr1_dataset/preprocessed_images/LSDS-2_Histology_M31-M32-1_ORO.npy\n",
      "Processing LOOCV for test image 18/33\n",
      "Test pred prob: 6.4990595e-09 True label: 0 test_image ../rr1_dataset/preprocessed_images/LSDS-2_Histology_M31-M32-2_ORO.npy\n",
      "Processing LOOCV for test image 19/33\n",
      "Test pred prob: 0.9998549 True label: 0 test_image ../rr1_dataset/preprocessed_images/LSDS-2_Histology_M31-M32-3_ORO.npy\n",
      "Processing LOOCV for test image 20/33\n",
      "Test pred prob: 1.939595e-08 True label: 0 test_image ../rr1_dataset/preprocessed_images/LSDS-2_Histology_M36-M37-M38-1_ORO.npy\n",
      "Processing LOOCV for test image 21/33\n",
      "Test pred prob: 2.8182867e-11 True label: 0 test_image ../rr1_dataset/preprocessed_images/LSDS-2_Histology_M36-M37-M38-2_ORO.npy\n",
      "Processing LOOCV for test image 22/33\n",
      "Test pred prob: 7.753368e-09 True label: 0 test_image ../rr1_dataset/preprocessed_images/LSDS-2_Histology_M36-M37-M38-3_ORO.npy\n",
      "Processing LOOCV for test image 23/33\n",
      "Test pred prob: 1.9936153e-10 True label: 0 test_image ../rr1_dataset/preprocessed_images/LSDS-2_Histology_M36-M37-M38-4_ORO.npy\n",
      "Processing LOOCV for test image 24/33\n",
      "Test pred prob: 0.07664235 True label: 0 test_image ../rr1_dataset/preprocessed_images/LSDS-2_Histology_M39-M40-1_ORO.npy\n",
      "Processing LOOCV for test image 25/33\n",
      "Test pred prob: 5.017347e-08 True label: 0 test_image ../rr1_dataset/preprocessed_images/LSDS-2_Histology_M39-M40-2_ORO.npy\n",
      "Processing LOOCV for test image 26/33\n",
      "Test pred prob: 2.617704e-11 True label: 0 test_image ../rr1_dataset/preprocessed_images/LSDS-2_Histology_M39-M40-3_ORO.npy\n",
      "Processing LOOCV for test image 27/33\n",
      "Test pred prob: 4.3509053e-06 True label: 0 test_image ../rr1_dataset/preprocessed_images/LSDS-2_Histology_M4-M5-M7-1_ORO.npy\n",
      "Processing LOOCV for test image 28/33\n",
      "Test pred prob: 0.9357992 True label: 0 test_image ../rr1_dataset/preprocessed_images/LSDS-2_Histology_M4-M5-M7-2_ORO.npy\n",
      "Processing LOOCV for test image 29/33\n",
      "Test pred prob: 3.7687627e-07 True label: 0 test_image ../rr1_dataset/preprocessed_images/LSDS-2_Histology_M4-M5-M7-3_ORO.npy\n",
      "Processing LOOCV for test image 30/33\n",
      "Test pred prob: 0.00026954367 True label: 0 test_image ../rr1_dataset/preprocessed_images/LSDS-2_Histology_M4-M5-M7-4_ORO.npy\n",
      "Processing LOOCV for test image 31/33\n",
      "Test pred prob: 0.0075629875 True label: 0 test_image ../rr1_dataset/preprocessed_images/LSDS-2_Histology_M8-M10-1_ORO.npy\n",
      "Processing LOOCV for test image 32/33\n",
      "Test pred prob: 4.1085186e-06 True label: 0 test_image ../rr1_dataset/preprocessed_images/LSDS-2_Histology_M8-M10-2_ORO.npy\n",
      "Processing LOOCV for test image 33/33\n",
      "Test pred prob: 8.329388e-05 True label: 0 test_image ../rr1_dataset/preprocessed_images/LSDS-2_Histology_M8-M10-3_ORO.npy\n",
      "Final model saved to ../Models\\rr1_cnn_224.pth\n"
     ]
    }
   ],
   "source": [
    "true_labels, image_pred_prob = loocv_full_image_with_augmentation(image_paths, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the cutoff value\n",
    "cutoff = 0.5\n",
    "# Convert to 0 and 1 based on the cutoff\n",
    "image_pred_label = (np.array(image_pred_prob) > cutoff).astype(int)\n",
    "image_pred_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOOCV Image-Level Accuracy: 0.82\n",
      "Precision: 0.83\n",
      "Recall: 0.82\n",
      "F1-Score: 0.82\n",
      "AUC Score: 0.85\n"
     ]
    }
   ],
   "source": [
    "# Calculate metrics\n",
    "accuracy = accuracy_score(true_labels, image_pred_label)\n",
    "precision = precision_score(true_labels, image_pred_label, average='weighted')\n",
    "recall = recall_score(true_labels, image_pred_label, average='weighted')\n",
    "f1 = f1_score(true_labels, image_pred_label, average='weighted')\n",
    "auc = roc_auc_score(true_labels, image_pred_prob, average='weighted')\n",
    "\n",
    "print(f\"LOOCV Image-Level Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1-Score: {f1:.2f}\")\n",
    "print(f\"AUC Score: {auc:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.832612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F1 Score</td>\n",
       "      <td>0.822314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AUC</td>\n",
       "      <td>0.852174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Metric     Value\n",
       "0   Accuracy  0.818182\n",
       "1  Precision  0.832612\n",
       "2     Recall  0.818182\n",
       "3   F1 Score  0.822314\n",
       "4        AUC  0.852174"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "locv_results_df = pd.DataFrame({'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'AUC'],\n",
    "    'Value': [accuracy, precision, recall, f1, auc]})\n",
    "locv_results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL_TORCH",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
